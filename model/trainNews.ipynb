{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "trainNews.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/CSID-DGU/2020-2-OSSP1-WhatsUp-5/blob/master/model/trainNews.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VF448dERVZsT",
        "outputId": "4c74705e-dbea-462d-8ac6-1a4ec6f6da5a"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zrtf4sLXV9uj",
        "outputId": "fd795122-272c-44fc-b057-2d25c494077c"
      },
      "source": [
        "cd \"/content/drive/Shareddrives/와썹_공개SW/GPT2_MNews\""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/Shareddrives/와썹_공개SW/GPT2_MNews\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DNr2zyTIRhYW"
      },
      "source": [
        "기존의 SKT-AI의 환경설정 sentencepiece >= 0.1.85를 sentencepiece == 0.1.85로 변경"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GYs-gDlT4uU_",
        "outputId": "304e25ff-537d-482d-9dc8-831ff3bb53b3"
      },
      "source": [
        "!pip install -r requirements.txt"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting gluonnlp==0.9.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/c6/27/07b57d22496ed6c98b247e578712122402487f5c265ec70a747900f97060/gluonnlp-0.9.1.tar.gz (252kB)\n",
            "\u001b[K     |████████████████████████████████| 256kB 8.6MB/s \n",
            "\u001b[?25hCollecting sentencepiece>=0.1.85\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/e5/2d/6d4ca4bef9a67070fa1cac508606328329152b1df10bdf31fb6e4e727894/sentencepiece-0.1.94-cp36-cp36m-manylinux2014_x86_64.whl (1.1MB)\n",
            "\u001b[K     |████████████████████████████████| 1.1MB 11.3MB/s \n",
            "\u001b[?25hCollecting transformers==2.11.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/48/35/ad2c5b1b8f99feaaf9d7cdadaeef261f098c6e1a6a2935d4d07662a6b780/transformers-2.11.0-py3-none-any.whl (674kB)\n",
            "\u001b[K     |████████████████████████████████| 675kB 15.0MB/s \n",
            "\u001b[?25hCollecting mxnet==1.6.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/81/f5/d79b5b40735086ff1100c680703e0f3efc830fa455e268e9e96f3c857e93/mxnet-1.6.0-py2.py3-none-any.whl (68.7MB)\n",
            "\u001b[K     |████████████████████████████████| 68.7MB 45kB/s \n",
            "\u001b[?25hCollecting kss\n",
            "  Downloading https://files.pythonhosted.org/packages/fc/bb/4772901b3b934ac204f32a0bd6fc0567871d8378f9bbc7dd5fd5e16c6ee7/kss-1.3.1.tar.gz\n",
            "Collecting jamo\n",
            "  Downloading https://files.pythonhosted.org/packages/ac/cc/49812faae67f9a24be6ddaf58a2cf7e8c3cbfcf5b762d9414f7103d2ea2c/jamo-0.4.1-py3-none-any.whl\n",
            "Requirement already satisfied: numpy>=1.16.0 in /usr/local/lib/python3.6/dist-packages (from gluonnlp==0.9.1->-r requirements.txt (line 1)) (1.18.5)\n",
            "Requirement already satisfied: cython in /usr/local/lib/python3.6/dist-packages (from gluonnlp==0.9.1->-r requirements.txt (line 1)) (0.29.21)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from gluonnlp==0.9.1->-r requirements.txt (line 1)) (20.7)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers==2.11.0->-r requirements.txt (line 3)) (3.0.12)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers==2.11.0->-r requirements.txt (line 3)) (4.41.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers==2.11.0->-r requirements.txt (line 3)) (2.23.0)\n",
            "Collecting sacremoses\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7d/34/09d19aff26edcc8eb2a01bed8e98f13a1537005d31e95233fd48216eed10/sacremoses-0.0.43.tar.gz (883kB)\n",
            "\u001b[K     |████████████████████████████████| 890kB 51.5MB/s \n",
            "\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers==2.11.0->-r requirements.txt (line 3)) (2019.12.20)\n",
            "Requirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from transformers==2.11.0->-r requirements.txt (line 3)) (0.8)\n",
            "Collecting tokenizers==0.7.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/14/e5/a26eb4716523808bb0a799fcfdceb6ebf77a18169d9591b2f46a9adb87d9/tokenizers-0.7.0-cp36-cp36m-manylinux1_x86_64.whl (3.8MB)\n",
            "\u001b[K     |████████████████████████████████| 3.8MB 52.5MB/s \n",
            "\u001b[?25hCollecting graphviz<0.9.0,>=0.8.1\n",
            "  Downloading https://files.pythonhosted.org/packages/53/39/4ab213673844e0c004bed8a0781a0721a3f6bb23eb8854ee75c236428892/graphviz-0.8.4-py2.py3-none-any.whl\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from packaging->gluonnlp==0.9.1->-r requirements.txt (line 1)) (2.4.7)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers==2.11.0->-r requirements.txt (line 3)) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers==2.11.0->-r requirements.txt (line 3)) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers==2.11.0->-r requirements.txt (line 3)) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers==2.11.0->-r requirements.txt (line 3)) (2020.12.5)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers==2.11.0->-r requirements.txt (line 3)) (1.15.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers==2.11.0->-r requirements.txt (line 3)) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers==2.11.0->-r requirements.txt (line 3)) (0.17.0)\n",
            "Building wheels for collected packages: gluonnlp, kss, sacremoses\n",
            "  Building wheel for gluonnlp (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for gluonnlp: filename=gluonnlp-0.9.1-cp36-cp36m-linux_x86_64.whl size=470033 sha256=763d42190f68adc3e22d5074a8517f56c6bedf7f0b74a0c0189f214fda139f7f\n",
            "  Stored in directory: /root/.cache/pip/wheels/af/60/16/1f8a40e68b85bd9bd7960e91830bca5e40cd113f3220b7e231\n",
            "  Building wheel for kss (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for kss: filename=kss-1.3.1-cp36-cp36m-linux_x86_64.whl size=251547 sha256=620d42d8f897d263bba9397e4c81eb3047a8bbb42693bd6dd71ea7a4cff383ff\n",
            "  Stored in directory: /root/.cache/pip/wheels/8b/98/d1/53f75f89925cd95779824778725ee3fa36e7aa55ed26ad54a8\n",
            "  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sacremoses: filename=sacremoses-0.0.43-cp36-none-any.whl size=893261 sha256=fe62cb906183e1d4920c8c35998a727c5764d6e3e9a3e760df3732a4fff8e977\n",
            "  Stored in directory: /root/.cache/pip/wheels/29/3c/fd/7ce5c3f0666dab31a50123635e6fb5e19ceb42ce38d4e58f45\n",
            "Successfully built gluonnlp kss sacremoses\n",
            "Installing collected packages: gluonnlp, sentencepiece, sacremoses, tokenizers, transformers, graphviz, mxnet, kss, jamo\n",
            "  Found existing installation: graphviz 0.10.1\n",
            "    Uninstalling graphviz-0.10.1:\n",
            "      Successfully uninstalled graphviz-0.10.1\n",
            "Successfully installed gluonnlp-0.9.1 graphviz-0.8.4 jamo-0.4.1 kss-1.3.1 mxnet-1.6.0 sacremoses-0.0.43 sentencepiece-0.1.94 tokenizers-0.7.0 transformers-2.11.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "thu9G9VARjsp"
      },
      "source": [
        "# 허깅페이스의 transformers 라이브러리와 SKT KoGPT2 모델 기반으로 작성된 코드\n",
        "---환경 설정 때문에 위에서 skt꺼 import 함\n",
        "--추후에는 해당 git에 있는 requirements.txt만 임포트 하면 될 것이라고 생각함"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jb6fC9JQRu7r"
      },
      "source": [
        "\n",
        "모델을 학습하기 위해 필요한 3까지 모듈\n",
        "1. TFGPT2LMHeadModel: 문장 생성\n",
        "2. gluonnlp의 SentencepieceTokenizer\n",
        "3. nlp"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EMYfEkfJ4ut7"
      },
      "source": [
        "import os\n",
        "\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "\n",
        "import gluonnlp as nlp\n",
        "from gluonnlp.data import SentencepieceTokenizer\n",
        "from transformers import TFGPT2LMHeadModel\n",
        "\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "from nltk.tokenize import sent_tokenize"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3zlRNLWiRwvy"
      },
      "source": [
        "__init__ 함수에서 TFGPT2LMHeadModel을 생성해서 실행할 수 있게 구현함.\n",
        "\n",
        "\n",
        "\n",
        "```\n",
        "# self.gpt2(inputs)[0]\n",
        "```\n",
        "\n",
        "생성모델을 활용하기 위해서는 vocabulary에 대한 logit 값만 활용하도록 첫 번째 값인 last_hidden_states 출력"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0C_QcCXj4wBO"
      },
      "source": [
        "class GPT2Model(tf.keras.Model):\n",
        "    def __init__(self, dir_path):\n",
        "        super(GPT2Model, self).__init__()\n",
        "        self.gpt2 = TFGPT2LMHeadModel.from_pretrained(dir_path)\n",
        "        \n",
        "    def call(self, inputs):\n",
        "        return self.gpt2(inputs)[0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q2fRzhddR3uc"
      },
      "source": [
        "**학습 파라미터 내려받고 준비하기**\n",
        "\n",
        "학습된 파라미터가 koGPT2의 경우 huggingface에 모델로 등록돼 있지 않아 파라미터를 다운로드 해야함. gpt_ckpt 폴더에 다운된 파라미터 위치해 있음\n",
        "\n",
        "모델 리소스 경로를 객체를 생성할 때 인자로 전달하여 학습된 파라미터를 가지는 GPT2 모델 객체 선언"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KO0mmiNgSH9v"
      },
      "source": [
        "## 사전 학습된 모델을 활용해 언어 생성 결과 확인\n",
        "\n",
        "단어 하나가 주어지면 문장을 만들어주는 방식으로\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KuAHAdo-STgo"
      },
      "source": [
        "**토크나이저 생성**\n",
        "\n",
        "텍스트를 모델에 입력하려면 필요함. \n",
        "앞서 불러온 SentencepieceTokenizer와 nlp 모듈의 vocab 활용하여 단어 사전과 토크나이저 정의.\n",
        "\n",
        "\n",
        "> GPT2의 각 스페셜 토큰의 역할\n",
        "\n",
        "1.   <unk<unk>> 모르는 단어에 대한 토큰\n",
        "2.   <pad<pad>> 배치 데이터 길이 맞추는 용도\n",
        "3.   <s<s>> 문장의 시작을 알림\n",
        "4.   </s<s>> 문장의 종결을 알림"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n63Krj47TcPl"
      },
      "source": [
        "에폭수와 학습 정확도는 비례 but 텍스트 생성과는 반비례"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9SEbP3gf4xy8"
      },
      "source": [
        "BATCH_SIZE = 64\n",
        "NUM_EPOCHS = 100\n",
        "MAX_LEN = 20\n",
        "TOKENIZER_PATH = './gpt_ckpt/gpt2_kor_tokenizer.spiece'\n",
        "\n",
        "tokenizer = SentencepieceTokenizer(TOKENIZER_PATH, num_best=0, alpha=0)\n",
        "vocab = nlp.vocab.BERTVocab.from_sentencepiece(TOKENIZER_PATH,\n",
        "                                               mask_token=None,\n",
        "                                               sep_token=None,\n",
        "                                               cls_token=None,\n",
        "                                               unknown_token='<unk>',\n",
        "                                               padding_token='<pad>',\n",
        "                                               bos_token='<s>',\n",
        "                                               eos_token='</s>')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FDwz8P3iSzlx"
      },
      "source": [
        "# 기사 제목 텍스트 데이터 전처리하기\n",
        "\n",
        "미세 조정할 학습 데이터 구성"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UlfKZdPj5k7J"
      },
      "source": [
        "DATA_IN_PATH = '/content/drive/Shareddrives/와썹_공개SW/crawling_DATA/edited_csv/TITLE/'\n",
        "TRAIN_DATA_FILE = [\n",
        "                   'g_health_title_edit.csv',\n",
        "                   'health_chosun_title_edit.csv',\n",
        "                   'medi_gate_title_edit.csv',\n",
        "                   'medical_times_title_edit.csv',\n",
        "                   'titles_remove_duple.csv'\n",
        "                   ]\n",
        "\n",
        "#sents = [s[:-1] for s in open(DATA_IN_PATH + TRAIN_DATA_FILE).readlines()]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d13-znT-S8Of"
      },
      "source": [
        "토크나이저로 텍스트를 토큰화한 후 입력데이터와 출력 데이터로 구성.\n",
        "한 문장으로 이루어진 데이터는 문장 시작, 끝에 스페셜 토큰 할당\n",
        "\n",
        "입력데이터 tokens[:-1]로 맨 앞에서 맨 뒤 직전 토큰까지만 활용\n",
        "\n",
        "정답데이터를 tokens[1:]로 맨 앞 다음 토큰에서 맨 뒤 토큰까지 활용\n",
        "\n",
        "pad_sequences 함수를 통해 데이터 패딩 && np.array로 구성하여 학습데이터 준비"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jAQ1bUz36keX"
      },
      "source": [
        "import csv\n",
        "input_data = []\n",
        "output_data = []\n",
        "test=[]\n",
        "for datasets in TRAIN_DATA_FILE:\n",
        "  f_med=open(DATA_IN_PATH+datasets,'r',encoding='utf-8')\n",
        "  rdr=csv.reader(f_med)\n",
        "  \n",
        "  for line in rdr:\n",
        "    for s in line:\n",
        "      #print(s)\n",
        "      tokens = [vocab[vocab.bos_token],]  + vocab[tokenizer(s)] + [vocab[vocab.eos_token],]\n",
        "      input_data.append(tokens[:-1])\n",
        "      output_data.append(tokens[1:])\n",
        "\n",
        "input_data = pad_sequences(input_data, MAX_LEN, value=vocab[vocab.padding_token])\n",
        "output_data = pad_sequences(output_data, MAX_LEN, value=vocab[vocab.padding_token])\n",
        "\n",
        "input_data = np.array(input_data, dtype=np.int64)\n",
        "output_data = np.array(output_data, dtype=np.int64)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uMxWCcODwx6d"
      },
      "source": [
        "# 학습시작"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JohoTz2ZTB0h"
      },
      "source": [
        "**손실함수와 정확도 측정 함수**\n",
        "\n",
        "*loss_object*: 크로스 엔트로피로 손실 값을 측정하기 위한 객체\n",
        "\n",
        "*train_accuracy*: 정확도 측정을 위한 객체\n",
        "\n",
        "*loss_function:* 인자로 정답과 예측한 값을 받아서 두 개의 값을 비교해서 손실을 계산하며, real 값 중 0인 값 <PAD<PAD>>는 손실계산에서 뺌\n",
        "train_accuracy: 정확도를 체크\n",
        "\n",
        "\n",
        "\n",
        "```\n",
        "# tf.math.logical_not(tf.math.equal(real, vocab[vocab.padding_token]))\n",
        "```\n",
        "정답 real에 포함되는 값 중 vocab[vocab.padding__token]인 것은 <<PAD>PAD>를 의미하는 값. 해당 값들은 True(1)가 되고 이를 제외한 나머지 값들은 False(0)\n",
        "\n",
        "치환된 요소들에 logical_not 함수를 적용하면 0->1,1->0으로 바뀜\n",
        "\n",
        "변경된 값을 loss_*=mask에 요소 간에 곱을 해주면 <<PAD>PAD>값은 loss_계산에서 빠짐\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q9QdIUqVA3NQ"
      },
      "source": [
        "loss_object = tf.keras.losses.SparseCategoricalCrossentropy(\n",
        "    from_logits=True, reduction='none')\n",
        "\n",
        "train_accuracy = tf.keras.metrics.SparseCategoricalAccuracy(name='accuracy')\n",
        "\n",
        "def loss_function(real, pred):\n",
        "    mask = tf.math.logical_not(tf.math.equal(real, vocab[vocab.padding_token]))\n",
        "    loss_ = loss_object(real, pred)\n",
        "\n",
        "    mask = tf.cast(mask, dtype=loss_.dtype)\n",
        "    loss_ *= mask\n",
        "\n",
        "    return tf.reduce_mean(loss_)\n",
        "\n",
        "def accuracy_function(real, pred):\n",
        "    mask = tf.math.logical_not(tf.math.equal(real, vocab[vocab.padding_token]))\n",
        "    mask = tf.expand_dims(tf.cast(mask, dtype=pred.dtype), axis=-1)\n",
        "    pred *= mask    \n",
        "    acc = train_accuracy(real, pred)\n",
        "\n",
        "    return tf.reduce_mean(acc)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A5Ym-UtOEHWu"
      },
      "source": [
        "학습할 때 시간이 오래걸리기 때문에 콘솔창에 쳐주기\n",
        "\n",
        "```\n",
        "function ClickConnect(){\n",
        "console.log(\"Working\"); \n",
        "document.querySelector(\"colab-toolbar-button#connect\").click() \n",
        "}\n",
        "setInterval(ClickConnect,60000)\n",
        "```\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MZVnQtr15Iv9"
      },
      "source": [
        "BASE_MODEL_PATH = './gpt_ckpt'\n",
        "gpt_model = GPT2Model(BASE_MODEL_PATH)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EmqyGux7TQzW"
      },
      "source": [
        "gpt_model.compile을 통해 loss나 optimizer, metrics 등을 설정해서 미세조정 준비"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NMt1WKP3hjbZ"
      },
      "source": [
        "### checkpoint에서 가중치를 로드할 때만 사용!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DQdA19JNhDvp",
        "outputId": "4f463972-1e0a-4ad2-af30-3d80794f26a8"
      },
      "source": [
        "checkpoint_path = \"checkpoint/title/cp.ckpt\"\n",
        "checkpoint_dir = os.path.dirname(checkpoint_path)\n",
        "\n",
        "gpt_model = GPT2Model(BASE_MODEL_PATH)\n",
        "gpt_model.load_weights(checkpoint_path)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.training.tracking.util.CheckpointLoadStatus at 0x7f9a46efdda0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eNrS4M4x2IdB"
      },
      "source": [
        "# 학습하기"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bvb20cyb1Z9T"
      },
      "source": [
        "gpt_model.compile(loss=loss_function,\n",
        "              optimizer=tf.keras.optimizers.Adam(1e-4),\n",
        "              metrics=[accuracy_function])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ji-gOfPADKzH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e017fc6b-7a72-4e79-81c8-23f2782e55cb"
      },
      "source": [
        "checkpoint_path = \"checkpoint/title/cp.ckpt\"\n",
        "checkpoint_dir = os.path.dirname(checkpoint_path)\n",
        "\n",
        "# 모델의 가중치를 저장하는 콜백 만들기\n",
        "# period : 체크포인트 저장 에포크 주기\n",
        "cp_callback = tf.keras.callbacks.ModelCheckpoint(filepath=checkpoint_path,\n",
        "                                                 save_weights_only=True,\n",
        "                                                 verbose=1, save_freq=4118)\n",
        "\n",
        "history = gpt_model.fit(input_data, output_data, \n",
        "                    batch_size=BATCH_SIZE, epochs=NUM_EPOCHS,\n",
        "                    validation_split=0.1,callbacks=[cp_callback])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/indexed_slices.py:432: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1373/1373 [==============================] - 641s 467ms/step - loss: 0.4691 - accuracy_function: 0.6133 - val_loss: 5.5183 - val_accuracy_function: 0.5929\n",
            "Epoch 2/100\n",
            "1373/1373 [==============================] - 637s 464ms/step - loss: 0.4676 - accuracy_function: 0.5866 - val_loss: 5.5248 - val_accuracy_function: 0.5841\n",
            "Epoch 3/100\n",
            "1371/1373 [============================>.] - ETA: 0s - loss: 0.4668 - accuracy_function: 0.5823\n",
            "Epoch 00003: saving model to checkpoint/title/cp.ckpt\n",
            "1373/1373 [==============================] - 646s 471ms/step - loss: 0.4668 - accuracy_function: 0.5823 - val_loss: 5.5635 - val_accuracy_function: 0.5813\n",
            "Epoch 4/100\n",
            "1373/1373 [==============================] - 636s 463ms/step - loss: 0.4663 - accuracy_function: 0.5805 - val_loss: 5.5658 - val_accuracy_function: 0.5799\n",
            "Epoch 5/100\n",
            "1373/1373 [==============================] - 641s 467ms/step - loss: 0.4654 - accuracy_function: 0.5795 - val_loss: 5.5698 - val_accuracy_function: 0.5791\n",
            "Epoch 6/100\n",
            "1370/1373 [============================>.] - ETA: 1s - loss: 0.4648 - accuracy_function: 0.5788\n",
            "Epoch 00006: saving model to checkpoint/title/cp.ckpt\n",
            "1373/1373 [==============================] - 651s 474ms/step - loss: 0.4648 - accuracy_function: 0.5788 - val_loss: 5.5923 - val_accuracy_function: 0.5786\n",
            "Epoch 7/100\n",
            "1373/1373 [==============================] - 641s 467ms/step - loss: 0.4634 - accuracy_function: 0.5785 - val_loss: 5.6030 - val_accuracy_function: 0.5783\n",
            "Epoch 8/100\n",
            "1373/1373 [==============================] - 641s 467ms/step - loss: 0.4624 - accuracy_function: 0.5782 - val_loss: 5.5955 - val_accuracy_function: 0.5780\n",
            "Epoch 9/100\n",
            "1369/1373 [============================>.] - ETA: 1s - loss: 0.4615 - accuracy_function: 0.5780\n",
            "Epoch 00009: saving model to checkpoint/title/cp.ckpt\n",
            "1373/1373 [==============================] - 649s 473ms/step - loss: 0.4616 - accuracy_function: 0.5780 - val_loss: 5.6313 - val_accuracy_function: 0.5779\n",
            "Epoch 10/100\n",
            "1373/1373 [==============================] - 641s 467ms/step - loss: 0.4610 - accuracy_function: 0.5778 - val_loss: 5.6205 - val_accuracy_function: 0.5777\n",
            "Epoch 11/100\n",
            "1373/1373 [==============================] - 641s 467ms/step - loss: 0.4600 - accuracy_function: 0.5777 - val_loss: 5.6600 - val_accuracy_function: 0.5776\n",
            "Epoch 12/100\n",
            "1368/1373 [============================>.] - ETA: 2s - loss: 0.4593 - accuracy_function: 0.5776\n",
            "Epoch 00012: saving model to checkpoint/title/cp.ckpt\n",
            "1373/1373 [==============================] - 653s 475ms/step - loss: 0.4593 - accuracy_function: 0.5776 - val_loss: 5.6393 - val_accuracy_function: 0.5775\n",
            "Epoch 13/100\n",
            "1373/1373 [==============================] - 641s 467ms/step - loss: 0.4585 - accuracy_function: 0.5775 - val_loss: 5.6488 - val_accuracy_function: 0.5775\n",
            "Epoch 14/100\n",
            "1373/1373 [==============================] - 640s 466ms/step - loss: 0.4575 - accuracy_function: 0.5775 - val_loss: 5.6744 - val_accuracy_function: 0.5775\n",
            "Epoch 15/100\n",
            "1367/1373 [============================>.] - ETA: 2s - loss: 0.4571 - accuracy_function: 0.5775\n",
            "Epoch 00015: saving model to checkpoint/title/cp.ckpt\n",
            "1373/1373 [==============================] - 648s 472ms/step - loss: 0.4572 - accuracy_function: 0.5775 - val_loss: 5.6727 - val_accuracy_function: 0.5774\n",
            "Epoch 16/100\n",
            "1373/1373 [==============================] - 636s 463ms/step - loss: 0.4565 - accuracy_function: 0.5775 - val_loss: 5.6823 - val_accuracy_function: 0.5774\n",
            "Epoch 17/100\n",
            "1373/1373 [==============================] - 641s 467ms/step - loss: 0.4555 - accuracy_function: 0.5774 - val_loss: 5.6955 - val_accuracy_function: 0.5774\n",
            "Epoch 18/100\n",
            "1366/1373 [============================>.] - ETA: 3s - loss: 0.4546 - accuracy_function: 0.5774\n",
            "Epoch 00018: saving model to checkpoint/title/cp.ckpt\n",
            "1373/1373 [==============================] - 650s 473ms/step - loss: 0.4546 - accuracy_function: 0.5774 - val_loss: 5.7013 - val_accuracy_function: 0.5774\n",
            "Epoch 19/100\n",
            "1373/1373 [==============================] - 641s 467ms/step - loss: 0.4544 - accuracy_function: 0.5774 - val_loss: 5.7238 - val_accuracy_function: 0.5774\n",
            "Epoch 20/100\n",
            "1373/1373 [==============================] - 641s 467ms/step - loss: 0.4530 - accuracy_function: 0.5774 - val_loss: 5.7359 - val_accuracy_function: 0.5774\n",
            "Epoch 21/100\n",
            " 983/1373 [====================>.........] - ETA: 2:53 - loss: 0.4493 - accuracy_function: 0.5772"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1fksb_G2hq-j"
      },
      "source": [
        "# 모델 저장"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CamHyCJ0DLSJ"
      },
      "source": [
        "DATA_OUT_PATH = './mnews_title'\n",
        "model_name = \"final_loss0.4_acc0.5\"\n",
        "\n",
        "save_path = os.path.join(DATA_OUT_PATH, model_name)\n",
        "\n",
        "if not os.path.exists(save_path):\n",
        "    os.makedirs(save_path)\n",
        "\n",
        "gpt_model.gpt2.save_pretrained(save_path)\n",
        "\n",
        "loaded_gpt_model = GPT2Model(save_path)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}