{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Generate_Article(final).ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"Vk3KHH9603St","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1608190610869,"user_tz":-540,"elapsed":30095,"user":{"displayName":"박범수","photoUrl":"","userId":"03458312767754065955"}},"outputId":"16e1fb49-3658-4ff9-a6d9-c61ec31e4c4f"},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"EKRJhg2JSkBH","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1608190611369,"user_tz":-540,"elapsed":8084,"user":{"displayName":"박범수","photoUrl":"","userId":"03458312767754065955"}},"outputId":"aa38573d-9e29-45d1-a8db-1b33e8cba9e2"},"source":[" cd /content/drive/Shareddrives/와썹_공개SW/GPT2_MNews/"],"execution_count":2,"outputs":[{"output_type":"stream","text":["/content/drive/Shareddrives/와썹_공개SW/GPT2_MNews\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"3t2lCV4ZNfE6","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1608190636661,"user_tz":-540,"elapsed":33188,"user":{"displayName":"박범수","photoUrl":"","userId":"03458312767754065955"}},"outputId":"73c9c65c-9e18-41fa-ce0e-95b5950ae3f4"},"source":["!pip install -r requirements.txt"],"execution_count":3,"outputs":[{"output_type":"stream","text":["Collecting gluonnlp==0.9.1\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/c6/27/07b57d22496ed6c98b247e578712122402487f5c265ec70a747900f97060/gluonnlp-0.9.1.tar.gz (252kB)\n","\u001b[K     |████████████████████████████████| 256kB 12.8MB/s \n","\u001b[?25hCollecting sentencepiece>=0.1.85\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/e5/2d/6d4ca4bef9a67070fa1cac508606328329152b1df10bdf31fb6e4e727894/sentencepiece-0.1.94-cp36-cp36m-manylinux2014_x86_64.whl (1.1MB)\n","\u001b[K     |████████████████████████████████| 1.1MB 19.9MB/s \n","\u001b[?25hCollecting transformers==2.11.0\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/48/35/ad2c5b1b8f99feaaf9d7cdadaeef261f098c6e1a6a2935d4d07662a6b780/transformers-2.11.0-py3-none-any.whl (674kB)\n","\u001b[K     |████████████████████████████████| 675kB 53.1MB/s \n","\u001b[?25hCollecting mxnet==1.6.0\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/81/f5/d79b5b40735086ff1100c680703e0f3efc830fa455e268e9e96f3c857e93/mxnet-1.6.0-py2.py3-none-any.whl (68.7MB)\n","\u001b[K     |████████████████████████████████| 68.7MB 45kB/s \n","\u001b[?25hCollecting kss\n","  Downloading https://files.pythonhosted.org/packages/fc/bb/4772901b3b934ac204f32a0bd6fc0567871d8378f9bbc7dd5fd5e16c6ee7/kss-1.3.1.tar.gz\n","Collecting jamo\n","  Downloading https://files.pythonhosted.org/packages/ac/cc/49812faae67f9a24be6ddaf58a2cf7e8c3cbfcf5b762d9414f7103d2ea2c/jamo-0.4.1-py3-none-any.whl\n","Requirement already satisfied: numpy>=1.16.0 in /usr/local/lib/python3.6/dist-packages (from gluonnlp==0.9.1->-r requirements.txt (line 1)) (1.18.5)\n","Requirement already satisfied: cython in /usr/local/lib/python3.6/dist-packages (from gluonnlp==0.9.1->-r requirements.txt (line 1)) (0.29.21)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from gluonnlp==0.9.1->-r requirements.txt (line 1)) (20.7)\n","Collecting sacremoses\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7d/34/09d19aff26edcc8eb2a01bed8e98f13a1537005d31e95233fd48216eed10/sacremoses-0.0.43.tar.gz (883kB)\n","\u001b[K     |████████████████████████████████| 890kB 48.7MB/s \n","\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers==2.11.0->-r requirements.txt (line 3)) (2.23.0)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers==2.11.0->-r requirements.txt (line 3)) (4.41.1)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers==2.11.0->-r requirements.txt (line 3)) (3.0.12)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers==2.11.0->-r requirements.txt (line 3)) (2019.12.20)\n","Requirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from transformers==2.11.0->-r requirements.txt (line 3)) (0.8)\n","Collecting tokenizers==0.7.0\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/14/e5/a26eb4716523808bb0a799fcfdceb6ebf77a18169d9591b2f46a9adb87d9/tokenizers-0.7.0-cp36-cp36m-manylinux1_x86_64.whl (3.8MB)\n","\u001b[K     |████████████████████████████████| 3.8MB 52.5MB/s \n","\u001b[?25hCollecting graphviz<0.9.0,>=0.8.1\n","  Downloading https://files.pythonhosted.org/packages/53/39/4ab213673844e0c004bed8a0781a0721a3f6bb23eb8854ee75c236428892/graphviz-0.8.4-py2.py3-none-any.whl\n","Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from packaging->gluonnlp==0.9.1->-r requirements.txt (line 1)) (2.4.7)\n","Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers==2.11.0->-r requirements.txt (line 3)) (1.15.0)\n","Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers==2.11.0->-r requirements.txt (line 3)) (7.1.2)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers==2.11.0->-r requirements.txt (line 3)) (0.17.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers==2.11.0->-r requirements.txt (line 3)) (2020.12.5)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers==2.11.0->-r requirements.txt (line 3)) (3.0.4)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers==2.11.0->-r requirements.txt (line 3)) (2.10)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers==2.11.0->-r requirements.txt (line 3)) (1.24.3)\n","Building wheels for collected packages: gluonnlp, kss, sacremoses\n","  Building wheel for gluonnlp (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for gluonnlp: filename=gluonnlp-0.9.1-cp36-cp36m-linux_x86_64.whl size=470033 sha256=ce040569b86517ce74f651828fa0feb7e9707a3f10b8594f8cd9fb41a8158e46\n","  Stored in directory: /root/.cache/pip/wheels/af/60/16/1f8a40e68b85bd9bd7960e91830bca5e40cd113f3220b7e231\n","  Building wheel for kss (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for kss: filename=kss-1.3.1-cp36-cp36m-linux_x86_64.whl size=251531 sha256=20746aa0eb00f1f69d11cabbf8bc93d87e5d366588c54a93717700ef8ef99db6\n","  Stored in directory: /root/.cache/pip/wheels/8b/98/d1/53f75f89925cd95779824778725ee3fa36e7aa55ed26ad54a8\n","  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for sacremoses: filename=sacremoses-0.0.43-cp36-none-any.whl size=893261 sha256=1bc9a180a790af3ac0902a0702a0ea902a11dab9496f73dd082e18aa89189e62\n","  Stored in directory: /root/.cache/pip/wheels/29/3c/fd/7ce5c3f0666dab31a50123635e6fb5e19ceb42ce38d4e58f45\n","Successfully built gluonnlp kss sacremoses\n","Installing collected packages: gluonnlp, sentencepiece, sacremoses, tokenizers, transformers, graphviz, mxnet, kss, jamo\n","  Found existing installation: graphviz 0.10.1\n","    Uninstalling graphviz-0.10.1:\n","      Successfully uninstalled graphviz-0.10.1\n","Successfully installed gluonnlp-0.9.1 graphviz-0.8.4 jamo-0.4.1 kss-1.3.1 mxnet-1.6.0 sacremoses-0.0.43 sentencepiece-0.1.94 tokenizers-0.7.0 transformers-2.11.0\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"1A8Mz94jTCga","executionInfo":{"status":"ok","timestamp":1608190646686,"user_tz":-540,"elapsed":43104,"user":{"displayName":"박범수","photoUrl":"","userId":"03458312767754065955"}}},"source":["import os\n","\n","import numpy as np\n","import tensorflow as tf\n","\n","import gluonnlp as nlp\n","from gluonnlp.data import SentencepieceTokenizer\n","from transformers import TFGPT2LMHeadModel\n","\n","from tensorflow.keras.preprocessing.sequence import pad_sequences\n","\n","from nltk.tokenize import sent_tokenize\n","\n","import pandas as pd\n","import kss\n","import random\n","\n","from utils.utils import get_jongsung_TF\n","from tqdm import tqdm"],"execution_count":4,"outputs":[]},{"cell_type":"code","metadata":{"id":"QDBGvKX3UKxb","executionInfo":{"status":"ok","timestamp":1608190646688,"user_tz":-540,"elapsed":42968,"user":{"displayName":"박범수","photoUrl":"","userId":"03458312767754065955"}}},"source":["class GPT2Model(tf.keras.Model):\n","    def __init__(self, dir_path):\n","        super(GPT2Model, self).__init__()\n","        self.gpt2 = TFGPT2LMHeadModel.from_pretrained(dir_path)\n","        \n","    def call(self, inputs):\n","        return self.gpt2(inputs)[0]"],"execution_count":5,"outputs":[]},{"cell_type":"code","metadata":{"id":"1xWXq7x1U0Zc","executionInfo":{"status":"ok","timestamp":1608190647710,"user_tz":-540,"elapsed":43824,"user":{"displayName":"박범수","photoUrl":"","userId":"03458312767754065955"}}},"source":["TOKENIZER_PATH = './gpt_ckpt/gpt2_kor_tokenizer.spiece'\n","tokenizer = SentencepieceTokenizer(TOKENIZER_PATH, num_best=0, alpha=0)\n","vocab = nlp.vocab.BERTVocab.from_sentencepiece(TOKENIZER_PATH,\n","                                               mask_token=None,\n","                                               sep_token=None,\n","                                               cls_token=None,\n","                                               unknown_token='<unk>',\n","                                               padding_token='<pad>',\n","                                               bos_token='<s>',\n","                                               eos_token='</s>')"],"execution_count":6,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"0UPF_g-jzpax"},"source":["## 텍스트 생성-코드"]},{"cell_type":"code","metadata":{"id":"kYn1kze9SvH9","executionInfo":{"status":"ok","timestamp":1608190647711,"user_tz":-540,"elapsed":43523,"user":{"displayName":"박범수","photoUrl":"","userId":"03458312767754065955"}}},"source":["def tf_top_k_top_p_filtering(logits, top_k=0, top_p=0.0, filter_value=-99999):\n","    _logits = logits.numpy()\n","    top_k = min(top_k, logits.shape[-1])  \n","    if top_k > 0:\n","        indices_to_remove = logits < tf.math.top_k(logits, top_k)[0][..., -1, None]\n","        _logits[indices_to_remove] = filter_value\n","\n","    if top_p > 0.0:\n","        sorted_logits = tf.sort(logits, direction='DESCENDING')\n","        sorted_indices = tf.argsort(logits, direction='DESCENDING')\n","        cumulative_probs = tf.math.cumsum(tf.nn.softmax(sorted_logits, axis=-1), axis=-1)\n","\n","        sorted_indices_to_remove = cumulative_probs > top_p\n","        sorted_indices_to_remove = tf.concat([[False], sorted_indices_to_remove[..., :-1]], axis=0)\n","        indices_to_remove = sorted_indices[sorted_indices_to_remove].numpy().tolist()\n","        \n","        _logits[indices_to_remove] = filter_value\n","    return tf.constant([_logits])"],"execution_count":7,"outputs":[]},{"cell_type":"code","metadata":{"id":"Jc5UpJsiTRZB","executionInfo":{"status":"ok","timestamp":1608190647712,"user_tz":-540,"elapsed":43366,"user":{"displayName":"박범수","photoUrl":"","userId":"03458312767754065955"}}},"source":["# GPT Model을 활용한 텍스트 생성\n","def generate_sent(seed_word, model, max_step=400, greedy=False, top_k=0, top_p=0.):\n","    sent = seed_word\n","    toked = tokenizer(sent)\n","    for _ in tqdm(range(max_step)):\n","        input_ids = tf.constant([vocab[vocab.bos_token],]  + vocab[toked])[None, :] \n","        outputs = model(input_ids)[:, -1, :]\n","        if greedy:\n","            gen = vocab.to_tokens(tf.argmax(outputs, axis=-1).numpy().tolist()[0])\n","        else:\n","            output_logit = tf_top_k_top_p_filtering(outputs[0], top_k=top_k, top_p=top_p)\n","            gen = vocab.to_tokens(tf.random.categorical(output_logit, 1).numpy().tolist()[0])[0]\n","        if gen == '</s>':\n","            break\n","        #print(\"생성된 토큰 : \"+gen)\n","        sent += gen.replace('▁', ' ')\n","        toked = tokenizer(sent)\n","    return sent"],"execution_count":8,"outputs":[]},{"cell_type":"code","metadata":{"id":"CxgR7yjobvBo","executionInfo":{"status":"ok","timestamp":1608190647714,"user_tz":-540,"elapsed":43176,"user":{"displayName":"박범수","photoUrl":"","userId":"03458312767754065955"}}},"source":["# 불완전한 종결 문장 제거\r\n","def preprocessing(content):\r\n","    text = []\r\n","    article = \"\"\r\n","    for s in kss.split_sentences(content):\r\n","        text.append(s)\r\n","    if text[-1][-1] != '.':\r\n","        text = text[:-1]\r\n","    for t in text:\r\n","        article += t + \" \"\r\n","    return article"],"execution_count":9,"outputs":[]},{"cell_type":"code","metadata":{"id":"t7WH1rndQAAT","executionInfo":{"status":"ok","timestamp":1608190647716,"user_tz":-540,"elapsed":42937,"user":{"displayName":"박범수","photoUrl":"","userId":"03458312767754065955"}}},"source":["# DB에서 columns에 있는 열 중 랜덤한 정보를 가져온다.\r\n","def random_info(df, keyword, columns):\r\n","    column = random.choice(columns)\r\n","    for i in range(len(df)):\r\n","        if df.loc[i, 'disease'] == keyword:\r\n","            csv_text = df.loc[i, column]\r\n","            return csv_text \r\n","    return \"\""],"execution_count":10,"outputs":[]},{"cell_type":"code","metadata":{"id":"bcuMLi_YO43T","executionInfo":{"status":"ok","timestamp":1608190647717,"user_tz":-540,"elapsed":42754,"user":{"displayName":"박범수","photoUrl":"","userId":"03458312767754065955"}}},"source":["# 기사 생성\r\n","# return : title, content\r\n","def generate_article(keyword, title_path, content_path, df):\r\n","    title_model = GPT2Model(title_path)    # 제목 생성 모델 load\r\n","    title = generate_sent(keyword, title_model,top_k=0, top_p=0.90)     # 제목 생성 모델을 활용하여 기사 제목 생성 \r\n","    content_model = GPT2Model(content_path)     # 본문 생성 모델\r\n","\r\n","    # 본문 생성 모델의 input 값으로 제목을 넣기 위한 전처리\r\n","    # 제목이 '.' 으로 끝나지 않을시 .을 추가한다.\r\n","    title = title.strip()\r\n","    if title[-1] not in ['.', '?', '!']:\r\n","        title += '.'\r\n","    # 사용할지 말지 임의로 정하기\r\n","    #if '...' in title:\r\n","    #    title = title.split('...')[-1]\r\n","    #    if title[-1] not in ['.', '?', '!']:\r\n","    #        title += '.'\r\n","\r\n","    # 본문 생성모델의 input\r\n","    # 예) [기사 제목]. + [질병명] + 이란(란)\r\n","    input_text = title + keyword\r\n","\r\n","    # 종성에 따라 조사 추가    \r\n","    if get_jongsung_TF(keyword) == \"T\":\r\n","        input_text += '이란'\r\n","    else:\r\n","        input_text += '란'\r\n","\r\n","    content = generate_sent(input_text, content_model, top_k=40, top_p=0.90)    # 본문 생성 모델을 활용하여 기사 본문 생성\r\n","    content = content.replace(title, \"\").strip()\r\n","    content = preprocessing(content)        # 불완전한 종결문장 제거\r\n","\r\n","    csv_text = \"\"   # DB로 부터 불러올 데이터\r\n","    columns = ['cause', 'symptom', 'diagnosis', 'treat']\r\n","\r\n","    # 기사 본문에 질병의 증상, 진단, 치료, 원인을 다루는지 확인하고 없는 것만 columns에 추가\r\n","    if '증상' in content:\r\n","        columns.remove('symptom')\r\n","    if '진단' in content:\r\n","        columns.remove('diagnosis')\r\n","    if '치료' in content:\r\n","        columns.remove('treat')\r\n","    if '원인' in content:\r\n","        columns.remove('cause')\r\n","\r\n","    if columns:     # columns의 원소들 중 하나를 랜덤하게 선택하여 질병 정보를 출력\r\n","        csv_text = random_info(df=df, keyword=keyword, columns = columns)\r\n","\r\n","    content = content + csv_text    \r\n","    content = preprocessing(content)    # 불완전한 종결문장 제거, 공백 교정\r\n","    return title, content"],"execution_count":11,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"OWEDNOu6wpKH"},"source":["# Generate Article"]},{"cell_type":"code","metadata":{"id":"maBeNLrdUOlW","executionInfo":{"status":"ok","timestamp":1608190647718,"user_tz":-540,"elapsed":42215,"user":{"displayName":"박범수","photoUrl":"","userId":"03458312767754065955"}}},"source":["TITLE_MODEL_PATH = './mnews_title/maxlen20_loss0.36_acc0.56/'\n","CONTENT_MODEL_PATH = './final_model/psy_loss2.0_acc0.32/'"],"execution_count":12,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"xGOz_JYlQpD5","executionInfo":{"status":"ok","timestamp":1608190649117,"user_tz":-540,"elapsed":43283,"user":{"displayName":"박범수","photoUrl":"","userId":"03458312767754065955"}},"outputId":"79bcf67f-f668-46df-f8b9-d31e6bab7037"},"source":["df = pd.read_csv(\"./data/samsung_hospital_db.csv\")      # 질병 DB load\r\n","\r\n","# textming 모델에서 LDA 분석을 통하여 추출된 keyword LOAD\r\n","input_keyword_df = pd.read_csv(\"./data/disease_keyword.csv\")\r\n","\r\n","# 추출된 keywords에서 랜덤하게 keyword(질병명) 선택 기사 선택\r\n","idx = random.randint(0, len(input_keyword_df)-1)    \r\n","keyword = input_keyword_df.loc[idx, 'disease']\r\n","\r\n","print(\"Keyword:\", keyword)"],"execution_count":13,"outputs":[{"output_type":"stream","text":["Keyword: 폐경\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"6UtilmlQwSER","executionInfo":{"status":"ok","timestamp":1608190723110,"user_tz":-540,"elapsed":117025,"user":{"displayName":"박범수","photoUrl":"","userId":"03458312767754065955"}},"outputId":"97749e78-d26e-4d7a-a1b9-26a796f1484a"},"source":["title, content = generate_article(keyword=keyword, title_path=TITLE_MODEL_PATH, content_path=CONTENT_MODEL_PATH, df=df)"],"execution_count":14,"outputs":[{"output_type":"stream","text":["  4%|▍         | 17/400 [00:01<00:43,  8.84it/s]\n","100%|██████████| 400/400 [00:43<00:00,  9.23it/s]\n"],"name":"stderr"}]},{"cell_type":"markdown","metadata":{"id":"BY-cE0Ldwr31"},"source":["# Article"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":35},"id":"QIcSZO3yS9hA","executionInfo":{"status":"ok","timestamp":1608190723114,"user_tz":-540,"elapsed":116280,"user":{"displayName":"박범수","photoUrl":"","userId":"03458312767754065955"}},"outputId":"f881b4a6-57d6-48d2-da91-b5be2753ab83"},"source":["title"],"execution_count":15,"outputs":[{"output_type":"execute_result","data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'폐경무렵 생리량 늘면 건강하다? 어쩌면 ‘자궁건강 적신호’.'"]},"metadata":{"tags":[]},"execution_count":15}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":143},"id":"R_BHGDbwp4Y2","executionInfo":{"status":"ok","timestamp":1608190723115,"user_tz":-540,"elapsed":115855,"user":{"displayName":"박범수","photoUrl":"","userId":"03458312767754065955"}},"outputId":"8a5808d2-2a28-4020-9794-d7b8cb585f02"},"source":["content"],"execution_count":16,"outputs":[{"output_type":"execute_result","data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'폐경이란 여성호르몬 감소로 인해 임신이 어려워지는 상태를 말한다. 일반적으로 40세 이상이 되면 자궁수축호르몬인 에스트로겐이 급격히 떨어지면서 생리를 하지 않을 때와 같은 양으로 많아지고, 그 사이 호르몬 수치가 정상수준으로 돌아온다. 폐경무렵이면 임신에 더 좋다는 속설이 있다. 그러나 폐경무렵이면 호르몬이 감소해 자궁건강에 좋지 않다. 특히 폐경무렵이면 정상체중에 살더라도 출산 후 여성호르몬인 에스트로겐 수치가 높아지기는커녕 오히려 수치가 상승한다. 폐경무렵부터 자궁건강을 지키려면 월경이 시작되더라도 생리예정일보다 하루 빨리 규칙적으로 병원을 방문해 자궁검사를 받는 것이 좋다. 여성미한의원 조선화 원장은 “폐경무렵은 자궁근육층을 형성하는 에스트로겐이나 프로게스테론 같은 여성호르몬을 생성하는 에스트로겐 수치가 가장 높은 시기”라고 설명했다. 자궁에 혹이 생겨 생리를 하지 않는다면 괜찮지만, 혹이 생리기 시작한 경우에는 자궁이 점점 커지고 자궁근육층이 두터워지면서 통증이 심해질 수 있다. 또 에스트로겐의 경우 자궁과 난소의 평활근을 강화시키고 여성 호르몬의 생성을 감소시키며 자궁내막증식작용, 자궁근종, 자궁내막염 등 다양한 질환을 발생시키기도 한다. 특히 에스트로겐 분비가 급격히 증가한 폐경무렵의 경우 호르몬 불균형으로 인해 자궁내막증식작용이 발생해 자궁출혈이나 자궁내막염 등이 나타날 수 있으며 자궁염, 자궁근종 등 자궁질환을 악화시킬 수 있다. 또 출산 이후 생리가 끊기는 경우도 많다. 호르몬 불균형으로 자궁에 만성적인 염증이 발생함으로써 자궁근종, 자궁내막증 등의 질환이 발생, 생리가 잘 이루어지지 않는 것이다. 따라서 평소 임신가능여부를 꼭 확인해야 하며 무리한 다이어트나 지나친 음주, 흡연 등 여러 가지 생활습관을 개선해야한다. 생리가 불규칙해지면 ‘태아형성장애’라 하여 자궁건강에 문제가 생겨난다. '"]},"metadata":{"tags":[]},"execution_count":16}]},{"cell_type":"code","metadata":{"id":"NW__OGMHM5Eh"},"source":[""],"execution_count":null,"outputs":[]}]}